{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JosephWildey/MachineLearningModels/blob/main/Data_Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d8e7d016",
      "metadata": {
        "id": "d8e7d016"
      },
      "source": [
        "# Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee805be2",
      "metadata": {
        "id": "ee805be2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c8c3ff7",
      "metadata": {
        "id": "7c8c3ff7"
      },
      "source": [
        "# Importing the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e2d6a1fb",
      "metadata": {
        "id": "e2d6a1fb"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"/home/joe/Documents/ML-Resources/Dataset1.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f85a9d04",
      "metadata": {
        "id": "f85a9d04"
      },
      "source": [
        "The matrix of features will be \"X\", the dependent variable is \"Y\"\n",
        "iloc = locate indexes, which takes the indices of the rows and columns we want to extract. Starts with rows.\n",
        "When a lower and upper bound is not defined, python will take everything. [:] is an undefined upper and lower bound.\n",
        "[:-1] will take every item up to the last. Everytime.\n",
        "\n",
        "x is every column and row up to the last column\n",
        "y is the last column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8120a16b",
      "metadata": {
        "id": "8120a16b"
      },
      "outputs": [],
      "source": [
        "x = dataset.iloc[:, :-1].values\n",
        "y = dataset.iloc[:, -1].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ce5ce69",
      "metadata": {
        "id": "5ce5ce69",
        "outputId": "2a4847f0-840d-4714-d1c1-d91f45389085"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 nan]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' nan 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c35ac611",
      "metadata": {
        "id": "c35ac611",
        "outputId": "8daa2faf-c3cc-46ed-d43b-7df6bb040626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "13b60ada",
      "metadata": {
        "id": "13b60ada"
      },
      "source": [
        "# Taking care of missing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66dfa157",
      "metadata": {
        "id": "66dfa157"
      },
      "outputs": [],
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
        "imputer.fit(x[:, 1:3])\n",
        "x[:, 1:3] = imputer.transform(x[:, 1:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19786fd6",
      "metadata": {
        "scrolled": true,
        "id": "19786fd6",
        "outputId": "fb8607e9-6a1a-41da-e5fc-e778289ff942"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['France' 44.0 72000.0]\n",
            " ['Spain' 27.0 48000.0]\n",
            " ['Germany' 30.0 54000.0]\n",
            " ['Spain' 38.0 61000.0]\n",
            " ['Germany' 40.0 63777.77777777778]\n",
            " ['France' 35.0 58000.0]\n",
            " ['Spain' 38.77777777777778 52000.0]\n",
            " ['France' 48.0 79000.0]\n",
            " ['Germany' 50.0 83000.0]\n",
            " ['France' 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "61edae9e",
      "metadata": {
        "id": "61edae9e"
      },
      "source": [
        "# Encoding Categorical Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fbd41863",
      "metadata": {
        "id": "fbd41863"
      },
      "source": [
        "## Encoding the independent variable"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ec699e2c",
      "metadata": {
        "id": "ec699e2c"
      },
      "source": [
        "Use one hot encoding to make values binary, and ties outline column relationships.\n",
        "One hot encoding is done with ColumnTransform and OneHotEncoder.\n",
        "For transformer in ColumnTransformer we must specify a few arguments: the kind of transformation (encoding), what kind of encoding (one hot), and the indexes of the columns we want to encode. Also \"passthrough\" maintains columns that are not changed. Without it, we would only have the columns we transform.\n",
        "\n",
        "ColumnTransform has a method to fit its transformation to a matrix of variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1837c684",
      "metadata": {
        "id": "1837c684"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')\n",
        "x = np.array(ct.fit_transform(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a3290fc",
      "metadata": {
        "id": "8a3290fc",
        "outputId": "6b06fdb4-bc48-487a-b331-33b84bc8eb07"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [0.0 1.0 0.0 30.0 54000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 35.0 58000.0]\n",
            " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f5d5278",
      "metadata": {
        "id": "7f5d5278"
      },
      "source": [
        "## Encoding the dependent variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f9cdf6e",
      "metadata": {
        "id": "9f9cdf6e"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9145418d",
      "metadata": {
        "id": "9145418d",
        "outputId": "7d7542dc-a260-42f9-af27-092870d744f9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(y)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34e3d4f2",
      "metadata": {
        "id": "34e3d4f2"
      },
      "source": [
        "# Splitting the dataset into the Training dataset and Test dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba2f1a64",
      "metadata": {
        "id": "ba2f1a64"
      },
      "source": [
        "It's recommended you do a 80% split for the training size, and you do it after the split to avoid "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec3a9799",
      "metadata": {
        "id": "ec3a9799"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.2, random_state = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9eb123ce",
      "metadata": {
        "id": "9eb123ce",
        "outputId": "8813a0f7-d7d9-4dd1-f361-cb78de1b5faa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 38.77777777777778 52000.0]\n",
            " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
            " [1.0 0.0 0.0 44.0 72000.0]\n",
            " [0.0 0.0 1.0 38.0 61000.0]\n",
            " [0.0 0.0 1.0 27.0 48000.0]\n",
            " [1.0 0.0 0.0 48.0 79000.0]\n",
            " [0.0 1.0 0.0 50.0 83000.0]\n",
            " [1.0 0.0 0.0 35.0 58000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0f3ba9a",
      "metadata": {
        "id": "d0f3ba9a",
        "outputId": "37671ba5-3e3a-4532-af3f-1ba3ccbb207c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 30.0 54000.0]\n",
            " [1.0 0.0 0.0 37.0 67000.0]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8a484e38",
      "metadata": {
        "id": "8a484e38",
        "outputId": "56522c52-c3bd-4884-99c6-23743298a01d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 0 0 1 1 0 1]\n"
          ]
        }
      ],
      "source": [
        "print(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d728dc31",
      "metadata": {
        "id": "d728dc31",
        "outputId": "59472d8c-e461-4b1b-9672-3d2bee7b8935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1]\n"
          ]
        }
      ],
      "source": [
        "print(Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e68e37f2",
      "metadata": {
        "id": "e68e37f2"
      },
      "source": [
        "# Feature Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "10cad18a",
      "metadata": {
        "id": "10cad18a"
      },
      "source": [
        "Standard scaler will provide the standardization required for this dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d2a49f3",
      "metadata": {
        "id": "6d2a49f3"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train[:, 3:] = sc.fit_transform(X_train[:, 3:])\n",
        "X_test[:, 3:] = sc.transform(X_test[:, 3:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ff14138",
      "metadata": {
        "id": "4ff14138",
        "outputId": "5c193350-4ce4-4aa6-badf-94ccb4063827"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
            " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
            " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
            " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
            " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
            " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
            " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
            " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec9b27eb",
      "metadata": {
        "id": "ec9b27eb",
        "outputId": "1188851c-5aee-43c0-c497-450551882409"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 -1.4661817944830124 -0.9069571034860727]\n",
            " [1.0 0.0 0.0 -0.44973664397484414 0.2056403393225306]]\n"
          ]
        }
      ],
      "source": [
        "print(X_test)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "name": "Data Preprocessing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}